{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/hc4293/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/hc4293/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(filepath):\n",
    "    # stopwords and lemmatizer\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        text = file.read().lower()\n",
    "        sentences = re.split(r'[.!?]', text)\n",
    "    processed_sentences = []\n",
    "    for sentence in sentences:\n",
    "        # remove punctuation and tokenize\n",
    "        tokens = re.findall(r'\\b\\w+\\b',sentence)\n",
    "        # remove stopwords and lemmatize\n",
    "        tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "        if tokens:  # Avoid empty lists\n",
    "            processed_sentences.append(tokens)\n",
    "    \n",
    "    return processed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./data/shakespeare.txt\"\n",
    "data = preprocess_corpus(filepath=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_word2vec(sentences, vector_size=100, window=5, min_count=2, workers=4):\n",
    "    model = Word2Vec(sentences, vector_size=vector_size, window=window, min_count=min_count, workers=workers)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = train_word2vec(data)\n",
    "word2vec_model.save(\"./data/shakespeare_word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    [\"thou\", \"thee\"],\n",
    "    [\"love\", \"honour\"],\n",
    "    [\"dagger\", \"sword\"],\n",
    "    [\"villain\", \"knave\"],\n",
    "    [\"fair\", \"foul\"]  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'thou' and 'thee': 64.89%\n",
      "Similarity between 'love' and 'honour': 89.54%\n",
      "Similarity between 'dagger' and 'sword': 88.06%\n",
      "Similarity between 'villain' and 'knave': 94.36%\n",
      "Similarity between 'fair' and 'foul': 78.76%\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_similarity(model, examples):\n",
    "    for word1, word2 in examples:\n",
    "        similarity = model.wv.similarity(word1, word2)\n",
    "        print(f\"Similarity between '{word1}' and '{word2}': {similarity*100:.2f}%\")\n",
    "\n",
    "model_path = \"./data/shakespeare_word2vec.model\"\n",
    "word2vec_model = Word2Vec.load(model_path)\n",
    "demonstrate_similarity(word2vec_model,examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load GloVe embeddings\n",
    "def load_glove_embeddings(glove_file_path):\n",
    "    embeddings = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            embeddings[word] = vector\n",
    "    return embeddings\n",
    "\n",
    "# Demonstrate similarity\n",
    "def demonstrate_similarity_glove(embeddings, examples):\n",
    "    for word1, word2 in examples:\n",
    "        if word1 in embeddings and word2 in embeddings:\n",
    "            vec1, vec2 = embeddings[word1], embeddings[word2]\n",
    "            similarity = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "            print(f\"Similarity between '{word1}' and '{word2}': {similarity*100:.2f}%\")\n",
    "        else:\n",
    "            print(f\"One or both words not found in embeddings: '{word1}', '{word2}'\")\n",
    "\n",
    "# Load embeddings and test\n",
    "glove_file_path = \"./glove.6B.100d.txt\"\n",
    "glove_embeddings = load_glove_embeddings(glove_file_path)\n",
    "\n",
    "examples = [\n",
    "    [\"thou\", \"thee\"],\n",
    "    [\"love\", \"honour\"],\n",
    "    [\"dagger\", \"sword\"],\n",
    "    [\"villain\", \"knave\"],\n",
    "    [\"fair\", \"foul\"]\n",
    "]\n",
    "\n",
    "demonstrate_similarity_glove(glove_embeddings, examples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Write-Up**\n",
    "\n",
    "---\n",
    "\n",
    "#### **Text Preprocessing**\n",
    "The preprocessing function processes the Shakespearean text by:\n",
    "- Converting text to lowercase.\n",
    "- Tokenizing sentences using regular expressions.\n",
    "- Removing punctuation and stopwords.\n",
    "- Lemmatizing tokens to ensure that words like \"dagger\" and \"daggers\" are treated the same.\n",
    "\n",
    "This prepares the data for training meaningful embeddings.\n",
    "\n",
    "---\n",
    "\n",
    "#### **Training the Word2Vec Model**\n",
    "The Word2Vec model was trained on the preprocessed Shakespearean corpus with the following parameters:\n",
    "- **Vector Size**: 100\n",
    "- **Window Size**: 5 (context words to consider on each side)\n",
    "- **Minimum Count**: 2 (ignores words with frequency < 2)\n",
    "\n",
    "The model was saved as `shakespeare_word2vec.model` for later use.\n",
    "\n",
    "---\n",
    "\n",
    "#### Discussion:\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **Comparison with Pre-Trained Embeddings (Bonus)**\n",
    "To assess the performance, we compared the Shakespeare-trained embeddings with pre-trained Word2Vec embeddings (e.g., from Google News or GloVe):\n",
    "\n",
    "| Pair           | Word2Vec Model | GloVe |\n",
    "|----------------|-------------------|---------------------------|\n",
    "| \"thou-thee\"    | 64.89%           | 21.43%                    |\n",
    "| \"love-honour\"  | 89.54%           | 56.32%                    |\n",
    "| \"dagger-sword\" | 88.06%           | 67.12%                    |\n",
    "| \"villain-knave\"| 94.36%           | 49.89%                    |\n",
    "| \"fair-foul\"    | 78.76%           | 33.45%                    |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### **References**\n",
    "1. Shakespeare, W. *The Complete Works of William Shakespeare*. Project Gutenberg, [https://www.gutenberg.org/](https://www.gutenberg.org/).\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imgsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
